{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC EMS Incidents 2013-2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://data.cityofnewyork.us/Public-Safety/EMS-Incident-Dispatch-Data/76xm-jjuj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Case: Predict number of EMS calls incidents in order to be adequately prepared to handle all of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import itertools\n",
    "import warnings\n",
    "import sklearn\n",
    "\n",
    "from statsmodels.graphics.tsaplots import plot_pacf, plot_acf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from pandas import Grouper\n",
    "from matplotlib.pylab import rcParams\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from fbprophet import Prophet\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "coerced_data = pd.read_csv('../data/ems_datetime_fixed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "coerced_data = coerced_data.drop(['Unnamed: 0', 'INCIDENT_DATETIME'], axis=1).set_index('proper_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INITIAL_CALL_TYPE</th>\n",
       "      <th>INITIAL_SEVERITY_LEVEL_CODE</th>\n",
       "      <th>FINAL_CALL_TYPE</th>\n",
       "      <th>FINAL_SEVERITY_LEVEL_CODE</th>\n",
       "      <th>VALID_DISPATCH_RSPNS_TIME_INDC</th>\n",
       "      <th>DISPATCH_RESPONSE_SECONDS_QY</th>\n",
       "      <th>VALID_INCIDENT_RSPNS_TIME_INDC</th>\n",
       "      <th>INCIDENT_RESPONSE_SECONDS_QY</th>\n",
       "      <th>HELD_INDICATOR</th>\n",
       "      <th>INCIDENT_DISPOSITION_CODE</th>\n",
       "      <th>BOROUGH</th>\n",
       "      <th>ZIPCODE</th>\n",
       "      <th>POLICEPRECINCT</th>\n",
       "      <th>STANDBY_INDICATOR</th>\n",
       "      <th>Change_In_Severity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proper_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01 00:00:04</th>\n",
       "      <td>RESPIR</td>\n",
       "      <td>4</td>\n",
       "      <td>RESPIR</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>101</td>\n",
       "      <td>Y</td>\n",
       "      <td>797.0</td>\n",
       "      <td>N</td>\n",
       "      <td>82.0</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>10472.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01 00:00:19</th>\n",
       "      <td>CARD</td>\n",
       "      <td>3</td>\n",
       "      <td>CARD</td>\n",
       "      <td>3</td>\n",
       "      <td>Y</td>\n",
       "      <td>59</td>\n",
       "      <td>Y</td>\n",
       "      <td>851.0</td>\n",
       "      <td>N</td>\n",
       "      <td>93.0</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>10454.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01 00:01:04</th>\n",
       "      <td>ARREST</td>\n",
       "      <td>1</td>\n",
       "      <td>ARREST</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>29</td>\n",
       "      <td>Y</td>\n",
       "      <td>429.0</td>\n",
       "      <td>N</td>\n",
       "      <td>83.0</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11418.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01 00:01:16</th>\n",
       "      <td>SICK</td>\n",
       "      <td>6</td>\n",
       "      <td>SICK</td>\n",
       "      <td>6</td>\n",
       "      <td>Y</td>\n",
       "      <td>56</td>\n",
       "      <td>Y</td>\n",
       "      <td>828.0</td>\n",
       "      <td>N</td>\n",
       "      <td>82.0</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>10453.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01 00:01:26</th>\n",
       "      <td>INJURY</td>\n",
       "      <td>5</td>\n",
       "      <td>INJURY</td>\n",
       "      <td>5</td>\n",
       "      <td>Y</td>\n",
       "      <td>32</td>\n",
       "      <td>Y</td>\n",
       "      <td>856.0</td>\n",
       "      <td>N</td>\n",
       "      <td>82.0</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>10457.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    INITIAL_CALL_TYPE  INITIAL_SEVERITY_LEVEL_CODE  \\\n",
       "proper_time                                                          \n",
       "2013-01-01 00:00:04            RESPIR                            4   \n",
       "2013-01-01 00:00:19              CARD                            3   \n",
       "2013-01-01 00:01:04            ARREST                            1   \n",
       "2013-01-01 00:01:16              SICK                            6   \n",
       "2013-01-01 00:01:26            INJURY                            5   \n",
       "\n",
       "                    FINAL_CALL_TYPE  FINAL_SEVERITY_LEVEL_CODE  \\\n",
       "proper_time                                                      \n",
       "2013-01-01 00:00:04          RESPIR                          4   \n",
       "2013-01-01 00:00:19            CARD                          3   \n",
       "2013-01-01 00:01:04          ARREST                          1   \n",
       "2013-01-01 00:01:16            SICK                          6   \n",
       "2013-01-01 00:01:26          INJURY                          5   \n",
       "\n",
       "                    VALID_DISPATCH_RSPNS_TIME_INDC  \\\n",
       "proper_time                                          \n",
       "2013-01-01 00:00:04                              Y   \n",
       "2013-01-01 00:00:19                              Y   \n",
       "2013-01-01 00:01:04                              Y   \n",
       "2013-01-01 00:01:16                              Y   \n",
       "2013-01-01 00:01:26                              Y   \n",
       "\n",
       "                     DISPATCH_RESPONSE_SECONDS_QY  \\\n",
       "proper_time                                         \n",
       "2013-01-01 00:00:04                           101   \n",
       "2013-01-01 00:00:19                            59   \n",
       "2013-01-01 00:01:04                            29   \n",
       "2013-01-01 00:01:16                            56   \n",
       "2013-01-01 00:01:26                            32   \n",
       "\n",
       "                    VALID_INCIDENT_RSPNS_TIME_INDC  \\\n",
       "proper_time                                          \n",
       "2013-01-01 00:00:04                              Y   \n",
       "2013-01-01 00:00:19                              Y   \n",
       "2013-01-01 00:01:04                              Y   \n",
       "2013-01-01 00:01:16                              Y   \n",
       "2013-01-01 00:01:26                              Y   \n",
       "\n",
       "                     INCIDENT_RESPONSE_SECONDS_QY HELD_INDICATOR  \\\n",
       "proper_time                                                        \n",
       "2013-01-01 00:00:04                         797.0              N   \n",
       "2013-01-01 00:00:19                         851.0              N   \n",
       "2013-01-01 00:01:04                         429.0              N   \n",
       "2013-01-01 00:01:16                         828.0              N   \n",
       "2013-01-01 00:01:26                         856.0              N   \n",
       "\n",
       "                     INCIDENT_DISPOSITION_CODE BOROUGH  ZIPCODE  \\\n",
       "proper_time                                                       \n",
       "2013-01-01 00:00:04                       82.0   BRONX  10472.0   \n",
       "2013-01-01 00:00:19                       93.0   BRONX  10454.0   \n",
       "2013-01-01 00:01:04                       83.0  QUEENS  11418.0   \n",
       "2013-01-01 00:01:16                       82.0   BRONX  10453.0   \n",
       "2013-01-01 00:01:26                       82.0   BRONX  10457.0   \n",
       "\n",
       "                     POLICEPRECINCT STANDBY_INDICATOR  Change_In_Severity  \n",
       "proper_time                                                                \n",
       "2013-01-01 00:00:04            43.0                 N                   0  \n",
       "2013-01-01 00:00:19            40.0                 N                   0  \n",
       "2013-01-01 00:01:04           102.0                 N                   0  \n",
       "2013-01-01 00:01:16            46.0                 N                   0  \n",
       "2013-01-01 00:01:26            48.0                 N                   0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coerced_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of our goals is to measure the frequency of calls over different time periods, so we need a way to tally calls when we call the \"resample\" method. Here we'll add a column where we assign a simple value of 1 to every call, and soon we'll use it to tally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "coerced_data['count'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INITIAL_CALL_TYPE</th>\n",
       "      <th>INITIAL_SEVERITY_LEVEL_CODE</th>\n",
       "      <th>FINAL_CALL_TYPE</th>\n",
       "      <th>FINAL_SEVERITY_LEVEL_CODE</th>\n",
       "      <th>VALID_DISPATCH_RSPNS_TIME_INDC</th>\n",
       "      <th>DISPATCH_RESPONSE_SECONDS_QY</th>\n",
       "      <th>VALID_INCIDENT_RSPNS_TIME_INDC</th>\n",
       "      <th>INCIDENT_RESPONSE_SECONDS_QY</th>\n",
       "      <th>HELD_INDICATOR</th>\n",
       "      <th>INCIDENT_DISPOSITION_CODE</th>\n",
       "      <th>BOROUGH</th>\n",
       "      <th>ZIPCODE</th>\n",
       "      <th>POLICEPRECINCT</th>\n",
       "      <th>STANDBY_INDICATOR</th>\n",
       "      <th>Change_In_Severity</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>proper_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-01 00:00:04</th>\n",
       "      <td>RESPIR</td>\n",
       "      <td>4</td>\n",
       "      <td>RESPIR</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>101</td>\n",
       "      <td>Y</td>\n",
       "      <td>797.0</td>\n",
       "      <td>N</td>\n",
       "      <td>82.0</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>10472.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01 00:00:19</th>\n",
       "      <td>CARD</td>\n",
       "      <td>3</td>\n",
       "      <td>CARD</td>\n",
       "      <td>3</td>\n",
       "      <td>Y</td>\n",
       "      <td>59</td>\n",
       "      <td>Y</td>\n",
       "      <td>851.0</td>\n",
       "      <td>N</td>\n",
       "      <td>93.0</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>10454.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01 00:01:04</th>\n",
       "      <td>ARREST</td>\n",
       "      <td>1</td>\n",
       "      <td>ARREST</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>29</td>\n",
       "      <td>Y</td>\n",
       "      <td>429.0</td>\n",
       "      <td>N</td>\n",
       "      <td>83.0</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11418.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01 00:01:16</th>\n",
       "      <td>SICK</td>\n",
       "      <td>6</td>\n",
       "      <td>SICK</td>\n",
       "      <td>6</td>\n",
       "      <td>Y</td>\n",
       "      <td>56</td>\n",
       "      <td>Y</td>\n",
       "      <td>828.0</td>\n",
       "      <td>N</td>\n",
       "      <td>82.0</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>10453.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-01 00:01:26</th>\n",
       "      <td>INJURY</td>\n",
       "      <td>5</td>\n",
       "      <td>INJURY</td>\n",
       "      <td>5</td>\n",
       "      <td>Y</td>\n",
       "      <td>32</td>\n",
       "      <td>Y</td>\n",
       "      <td>856.0</td>\n",
       "      <td>N</td>\n",
       "      <td>82.0</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>10457.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    INITIAL_CALL_TYPE  INITIAL_SEVERITY_LEVEL_CODE  \\\n",
       "proper_time                                                          \n",
       "2013-01-01 00:00:04            RESPIR                            4   \n",
       "2013-01-01 00:00:19              CARD                            3   \n",
       "2013-01-01 00:01:04            ARREST                            1   \n",
       "2013-01-01 00:01:16              SICK                            6   \n",
       "2013-01-01 00:01:26            INJURY                            5   \n",
       "\n",
       "                    FINAL_CALL_TYPE  FINAL_SEVERITY_LEVEL_CODE  \\\n",
       "proper_time                                                      \n",
       "2013-01-01 00:00:04          RESPIR                          4   \n",
       "2013-01-01 00:00:19            CARD                          3   \n",
       "2013-01-01 00:01:04          ARREST                          1   \n",
       "2013-01-01 00:01:16            SICK                          6   \n",
       "2013-01-01 00:01:26          INJURY                          5   \n",
       "\n",
       "                    VALID_DISPATCH_RSPNS_TIME_INDC  \\\n",
       "proper_time                                          \n",
       "2013-01-01 00:00:04                              Y   \n",
       "2013-01-01 00:00:19                              Y   \n",
       "2013-01-01 00:01:04                              Y   \n",
       "2013-01-01 00:01:16                              Y   \n",
       "2013-01-01 00:01:26                              Y   \n",
       "\n",
       "                     DISPATCH_RESPONSE_SECONDS_QY  \\\n",
       "proper_time                                         \n",
       "2013-01-01 00:00:04                           101   \n",
       "2013-01-01 00:00:19                            59   \n",
       "2013-01-01 00:01:04                            29   \n",
       "2013-01-01 00:01:16                            56   \n",
       "2013-01-01 00:01:26                            32   \n",
       "\n",
       "                    VALID_INCIDENT_RSPNS_TIME_INDC  \\\n",
       "proper_time                                          \n",
       "2013-01-01 00:00:04                              Y   \n",
       "2013-01-01 00:00:19                              Y   \n",
       "2013-01-01 00:01:04                              Y   \n",
       "2013-01-01 00:01:16                              Y   \n",
       "2013-01-01 00:01:26                              Y   \n",
       "\n",
       "                     INCIDENT_RESPONSE_SECONDS_QY HELD_INDICATOR  \\\n",
       "proper_time                                                        \n",
       "2013-01-01 00:00:04                         797.0              N   \n",
       "2013-01-01 00:00:19                         851.0              N   \n",
       "2013-01-01 00:01:04                         429.0              N   \n",
       "2013-01-01 00:01:16                         828.0              N   \n",
       "2013-01-01 00:01:26                         856.0              N   \n",
       "\n",
       "                     INCIDENT_DISPOSITION_CODE BOROUGH  ZIPCODE  \\\n",
       "proper_time                                                       \n",
       "2013-01-01 00:00:04                       82.0   BRONX  10472.0   \n",
       "2013-01-01 00:00:19                       93.0   BRONX  10454.0   \n",
       "2013-01-01 00:01:04                       83.0  QUEENS  11418.0   \n",
       "2013-01-01 00:01:16                       82.0   BRONX  10453.0   \n",
       "2013-01-01 00:01:26                       82.0   BRONX  10457.0   \n",
       "\n",
       "                     POLICEPRECINCT STANDBY_INDICATOR  Change_In_Severity  \\\n",
       "proper_time                                                                 \n",
       "2013-01-01 00:00:04            43.0                 N                   0   \n",
       "2013-01-01 00:00:19            40.0                 N                   0   \n",
       "2013-01-01 00:01:04           102.0                 N                   0   \n",
       "2013-01-01 00:01:16            46.0                 N                   0   \n",
       "2013-01-01 00:01:26            48.0                 N                   0   \n",
       "\n",
       "                     count  \n",
       "proper_time                 \n",
       "2013-01-01 00:00:04      1  \n",
       "2013-01-01 00:00:19      1  \n",
       "2013-01-01 00:01:04      1  \n",
       "2013-01-01 00:01:16      1  \n",
       "2013-01-01 00:01:26      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coerced_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "coerced_data.index = pd.to_datetime(coerced_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = coerced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "burns = df[(df['INITIAL_CALL_TYPE'] == 'BURNMA')]['BOROUGH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bar() missing 1 required positional argument: 'height'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-a67ce7c15c9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mburns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: bar() missing 1 required positional argument: 'height'"
     ]
    }
   ],
   "source": [
    "plt.plot(burns.value_counts(), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Exogenous Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = pd.read_csv('weather_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data.index = pd.to_datetime(weather_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_average_temperature_data = pd.DataFrame(weather_data['Avg Temp'].resample('W').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_sum_precipitation = pd.DataFrame(weather_data['Precipitation Water Equiv'].resample('W').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_sum_snowfall = pd.DataFrame(weather_data['Snowfall'].resample('W').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_data = pd.read_csv('holiday_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_data.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_data.index = pd.to_datetime(holiday_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_sum_holidays = holiday_data.resample('W').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_sum_holidays.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have a time series to play with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(coerced_data['count'].resample('W').sum()) - 26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_call_volume = coerced_data['count'].resample('W').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_call_volume = coerced_data['count'].resample('D').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_average_response_time = coerced_data['INCIDENT_RESPONSE_SECONDS_QY'].resample('W').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_average_response_time = weekly_average_response_time / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_average_response_time = coerced_data['INCIDENT_RESPONSE_SECONDS_QY'].resample('D').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_average_response_time = daily_average_response_time / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_average_response_time_df = pd.DataFrame(data=weekly_average_response_time, index=weekly_average_response_time.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_average_response_time_df = pd.merge(weekly_average_response_time_df, weekly_average_temperature_data, left_index=True, right_index=True)\n",
    "weekly_average_response_time_df = pd.merge(weekly_average_response_time_df, weekly_sum_precipitation, left_index=True, right_index=True)\n",
    "weekly_average_response_time_df = pd.merge(weekly_average_response_time_df, weekly_sum_snowfall, left_index=True, right_index=True)\n",
    "weekly_average_response_time_df = pd.merge(weekly_average_response_time_df, weekly_sum_holidays, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_average_response_time_df.columns = ['avg_response_time_min', 'avg_temp', 'total_precip', 'total_snowfall', 'total_holidays']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_average_response_time_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_call_volume_df = pd.DataFrame(data=weekly_call_volume, index=weekly_call_volume.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_call_volume_df = pd.merge(weekly_call_volume_df, weekly_average_temperature_data, left_index=True, right_index=True)\n",
    "weekly_call_volume_df = pd.merge(weekly_call_volume_df, weekly_sum_precipitation, left_index=True, right_index=True)\n",
    "weekly_call_volume_df = pd.merge(weekly_call_volume_df, weekly_sum_snowfall, left_index=True, right_index=True)\n",
    "weekly_call_volume_df = pd.merge(weekly_call_volume_df, weekly_sum_holidays, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_call_volume_df.columns = ['sum of weekly calls', 'avg_temp', 'total_precip', 'total_snowfall', 'total_holidays']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_call_volume_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see what this all looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def dickey_fuller(ser):\n",
    "    #Perform Dickey-Fuller test:\n",
    "    print ('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(ser.values)\n",
    "\n",
    "    # Extract and display test results in a user friendly manner\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print (dfoutput)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(weekly_average_response_time_df['avg_temp'])\n",
    "plt.show()\n",
    "dickey_fuller(weekly_average_response_time_df['avg_temp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(weekly_average_response_time_df['total_precip'])\n",
    "plt.show()\n",
    "dickey_fuller(weekly_average_response_time_df['total_precip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(weekly_average_response_time_df['total_snowfall'])\n",
    "plt.show()\n",
    "dickey_fuller(weekly_average_response_time_df['total_snowfall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(weekly_average_response_time_df['total_holidays'])\n",
    "plt.show()\n",
    "dickey_fuller(weekly_average_response_time_df['total_holidays'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(weekly_call_volume)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(weekly_average_response_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dickey_fuller(weekly_call_volume), print('\\n'), dickey_fuller(weekly_average_response_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dickey_fuller(daily_average_response_time), dickey_fuller(daily_call_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, we get a decent P-val for our stationarity check, but we know we can do better. There must be seasonality to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for year in [2013, 2014, 2015, 2016, 2017]:\n",
    "#     print('\\n' + str(year) + '\\n')\n",
    "#     print(dickey_fuller(weekly_average_response_time['{}-01-01'.format(str(year)):'{}-12-31'.format(str(year))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_statistics(timeseries):\n",
    "    rolmean = timeseries.rolling(window = 8, center = False).mean()\n",
    "    rolstd = timeseries.rolling(window = 8, center = False).std()\n",
    "    fig = plt.figure(figsize=(12,7))\n",
    "    orig = plt.plot(timeseries, color='blue',label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_statistics(weekly_average_response_time)\n",
    "rolling_statistics(weekly_call_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_statistics(daily_average_response_time)\n",
    "rolling_statistics(daily_call_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = seasonal_decompose(weekly_average_response_time, freq=52)  \n",
    "fig = plt.figure()  \n",
    "fig = decomposition.plot()  \n",
    "fig.set_size_inches(15, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition = seasonal_decompose(daily_average_response_time, freq=365)  \n",
    "fig = plt.figure()  \n",
    "fig = decomposition.plot()  \n",
    "fig.set_size_inches(15, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the first difference between weeks to improve stationarity. We tried taking a seasonal difference, but it didn't improve our DF score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log mode:\n",
    "# weekly_average_response_time = weekly_average_response_time.apply(lambda x: np.log(x))\n",
    "# Tried this, didn't help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_first_diff = weekly_average_response_time - weekly_average_response_time.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_first_diff = daily_average_response_time - daily_average_response_time.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_first_diff = week_first_diff.dropna()\n",
    "dickey_fuller(week_first_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_first_diff = daily_first_diff.dropna()\n",
    "dickey_fuller(daily_first_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 14, 5\n",
    "plot_acf(week_first_diff, lags = 10);\n",
    "\n",
    "rcParams['figure.figsize'] = 14, 5\n",
    "plot_pacf(week_first_diff, lags = 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 14, 5\n",
    "plot_acf(daily_first_diff, lags = 10);\n",
    "\n",
    "rcParams['figure.figsize'] = 14, 5\n",
    "plot_pacf(daily_first_diff, lags = 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal Difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_seasonal_difference = (weekly_average_response_time - weekly_average_response_time.shift(52)).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_seasonal_difference = (daily_average_response_time - daily_average_response_time.shift(52)).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dickey_fuller(weekly_seasonal_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dickey_fuller(daily_seasonal_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 14, 5\n",
    "plot_acf(weekly_seasonal_difference, lags = 10);\n",
    "\n",
    "rcParams['figure.figsize'] = 14, 5\n",
    "plot_pacf(weekly_seasonal_difference, lags = 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 14, 5\n",
    "plot_acf(daily_seasonal_difference, lags = 10);\n",
    "\n",
    "rcParams['figure.figsize'] = 14, 5\n",
    "plot_pacf(daily_seasonal_difference, lags = 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal FIRST Differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_seasonal_first_difference = (week_first_diff - week_first_diff.shift(52)).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_seasonal_first_difference = (daily_first_diff - daily_first_diff.shift(52)).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dickey_fuller(weekly_seasonal_first_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dickey_fuller(daily_seasonal_first_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 14, 5\n",
    "plot_acf(weekly_seasonal_first_difference, lags = 10);\n",
    "\n",
    "rcParams['figure.figsize'] = 14, 5\n",
    "plot_pacf(weekly_seasonal_first_difference, lags = 10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 14, 5\n",
    "plot_acf(daily_seasonal_first_difference, lags = 10);\n",
    "\n",
    "rcParams['figure.figsize'] = 14, 5\n",
    "plot_pacf(daily_seasonal_first_difference, lags = 10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SARIMA Step 1: Grid Search for Ideal Params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Test Train Split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endogenous_train = weekly_average_response_time[:-52]\n",
    "exogenous_train = weekly_average_response_time_df.drop(['avg_response_time_min'], axis=1)[:-52]\n",
    "endogenous_test = weekly_average_response_time[-52:]\n",
    "exogenous_test = weekly_average_response_time_df.drop(['avg_response_time_min'], axis=1)[-52:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the p, d and q parameters to take any value between 0 and 2\n",
    "p = d = q = range(0, 2)\n",
    "\n",
    "# Generate all different combinations of p, q and q triplets\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "# Generate all different combinations of seasonal p, q and q triplets\n",
    "pdqs = [(x[0], x[1], x[2], 52) for x in list(itertools.product(p, d, q))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run a grid with pdq and seasonal pdq parameters calculated above and get the best AIC value\n",
    "ans = []\n",
    "for comb in pdq:\n",
    "    for combs in pdqs:\n",
    "        try:\n",
    "            mod = sm.tsa.statespace.SARIMAX(weekly_average_response_time,\n",
    "                                            exog=weekly_average_response_time_df.drop(['avg_response_time_min'],                                                                                             axis=1),\n",
    "                                            order=comb,\n",
    "                                            seasonal_order=combs,\n",
    "                                            enforce_stationarity=False,\n",
    "                                            enforce_invertibility=False)\n",
    "\n",
    "            output = mod.fit()\n",
    "            ans.append([comb, combs, output.aic])\n",
    "            print('ARIMA {} x {}52 : AIC Calculated ={}'.format(comb, combs, output.aic))\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "# Find the parameters with minimal AIC value.\n",
    "\n",
    "ans_df = pd.DataFrame(ans, columns=['pdq', 'pdqs', 'aic'])\n",
    "ans_df.loc[ans_df['aic'].idxmin()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We noticed that when we grid search SARIMAX params with access to exogenous variables (and hold-out a testing set), we get slightly different SARIMAX params than if we were to run the grid search on all data (without exogenous vars)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now plug ideal params into SARIMAX model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ARIMA_MODEL = sm.tsa.statespace.SARIMAX(endogenous_train,\n",
    "                                        exog=exogenous_train,\n",
    "                                order=(1, 0, 1),\n",
    "                                seasonal_order=(0, 1, 1, 52),\n",
    "                                enforce_stationarity=False,\n",
    "                                enforce_invertibility=False)\n",
    "\n",
    "output = ARIMA_MODEL.fit()\n",
    "\n",
    "print(output.summary().tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.plot_diagnostics(figsize=(15, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dynamic predictions with confidence intervals as above.\n",
    "\n",
    "pred_static = output.get_prediction(start = endogenous_test.index[0],\n",
    "                                     end = endogenous_test.index[-1],\n",
    "                                     exog = exogenous_test,\n",
    "                                     dynamic = False, \n",
    "                                     full_results = True)\n",
    "\n",
    "pred_static_conf = pred_static.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the dynamic forecast with confidence intervals.\n",
    "\n",
    "ax = weekly_average_response_time[100:].plot(label='observed', figsize=(18, 6))\n",
    "pred_static.predicted_mean.plot(label='Static Forecast', ax=ax)\n",
    "\n",
    "# ax.fill_between(pred_static_conf.index,\n",
    "#                 pred_static_conf.iloc[:, 0],\n",
    "#                 pred_static_conf.iloc[:, 1], color='g', alpha=.3)\n",
    "\n",
    "ax.fill_betweenx(ax.get_ylim(), \n",
    "                 weekly_average_response_time[-52:].index[0], \n",
    "                 '2017-12-31', \n",
    "                 alpha=.1, zorder=-1)\n",
    "\n",
    "ax.set_xlabel('Week')\n",
    "ax.set_ylabel('Average Response Time')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictive Power: Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_time_mean = np.zeros((len(weekly_average_response_time),1))\n",
    "response_time_mean.fill(np.mean(weekly_average_response_time[:-52]))\n",
    "response_time_mean = pd.DataFrame(response_time_mean, \n",
    "                                      index=weekly_average_response_time.index)\n",
    "\n",
    "baseline_mse = np.mean((response_time_mean[-52:][0] - endogenous_test)**2)\n",
    "baseline_rmse = np.sqrt(baseline_mse)\n",
    "\n",
    "print('The MSE when guessing the mean is {}'.format(baseline_mse))\n",
    "print('The RMSE when guessing the mean is {}'.format(baseline_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = ((pred_static.predicted_mean - endogenous_test)**2).mean()\n",
    "rmse = np.sqrt(mse)\n",
    "print('The MSE for this model is {}'.format(mse))\n",
    "print('The RMSE for this model is {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facebook Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(weekly_average_response_time) # Formatting a DF how Prophet likes it\n",
    "df.columns = ['y']\n",
    "df['ds'] = df.index\n",
    "m = Prophet(weekly_seasonality=True)\n",
    "m.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future = m.make_future_dataframe(periods=52, freq='W')\n",
    "forecast = m.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.index = pd.date_range(start=df.index[0], periods=len(forecast), freq='W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "plt.plot(df['y']['2016-07-01':])\n",
    "plt.plot(forecast['yhat']['2016-07-01':])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "plt.plot(df['y']['2015-07-01':])\n",
    "plt.plot(forecast['yhat']['2015-07-01':])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = m.plot(forecast, xlabel='Date', ylabel='EMS Avg Response Time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's see what some multivariate stuff looks like "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a grid with pdq and seasonal pdq parameters calculated above and get the best AIC value\n",
    "ans = []\n",
    "for comb in pdq:\n",
    "    for combs in pdqs:\n",
    "        try:\n",
    "            mod = sm.tsa.statespace.SARIMAX(weekly_average_response_time,\n",
    "                                            order=comb,\n",
    "                                            seasonal_order=combs,\n",
    "                                            enforce_stationarity=False,\n",
    "                                            enforce_invertibility=False)\n",
    "\n",
    "            output = mod.fit()\n",
    "            ans.append([comb, combs, output.aic])\n",
    "            print('ARIMA {} x {}52 : AIC Calculated ={}'.format(comb, combs, output.aic))\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the parameters with minimal AIC value.\n",
    "\n",
    "ans_df = pd.DataFrame(ans, columns=['pdq', 'pdqs', 'aic'])\n",
    "ans_df.loc[ans_df['aic'].idxmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_average_response_time_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endogenous_train = weekly_average_response_time[:-52]\n",
    "exogenous_train = weekly_average_response_time_df.drop(['avg_response_time_min'], axis=1)[:-52]\n",
    "endogenous_test = weekly_average_response_time[-52:]\n",
    "exogenous_test = weekly_average_response_time_df.drop(['avg_response_time_min'], axis=1)[-52:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARIMA_MODEL = sm.tsa.statespace.SARIMAX(endogenous_train,\n",
    "                                exog = exogenous_train,\n",
    "                                order=(1, 0, 1),\n",
    "                                seasonal_order=(0, 1, 1, 52),\n",
    "                                enforce_stationarity=False,\n",
    "                                enforce_invertibility=False)\n",
    "\n",
    "output = ARIMA_MODEL.fit()\n",
    "\n",
    "print(output.summary().tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.plot_diagnostics(figsize=(15, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Static "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endogenous_test.index[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_f = output.get_forecast(steps=52, exog = exogenous_test)\n",
    "pred_conf_f = prediction_f.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = output.get_prediction(start = endogenous_test.index[0],\n",
    "                                    end = endogenous_test.index[-1],\n",
    "                                    exog = exogenous_test,\n",
    "                                    dynamic = False)\n",
    "\n",
    "pred_conf = prediction.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_conf_f.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_conf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the static forecast with confidence intervals.\n",
    "\n",
    "ax = weekly_average_response_time[-100:].plot(label='observed', figsize=(18, 6))\n",
    "prediction.predicted_mean.plot(label='Static Forecast', ax=ax)\n",
    "\n",
    "# ax.fill_between(pred_conf.index,\n",
    "#                 pred_conf.iloc[:, 0],\n",
    "#                 pred_conf.iloc[:, 1], color='g', alpha=.3)\n",
    "\n",
    "# ax.fill_betweenx(ax.get_ylim(), \n",
    "#                  weekly_average_response_time[-50:-49].index[0], \n",
    "#                  '2017-12-31', \n",
    "#                  alpha=.1, zorder=-1)\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Avg Weekly Call Time')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_time_mean = np.zeros((len(weekly_average_response_time),1))\n",
    "response_time_mean.fill(np.mean(weekly_average_response_time[:-52]))\n",
    "response_time_mean = pd.DataFrame(response_time_mean, \n",
    "                                      index=weekly_average_response_time.index)\n",
    "\n",
    "baseline_mse = np.mean((response_time_mean[-52:][0] - endogenous_test)**2)\n",
    "baseline_rmse = np.sqrt(baseline_mse)\n",
    "print('The MSE when guessing the mean is {}'.format(baseline_mse))\n",
    "print('The RMSE when guessing the mean is {}'.format(baseline_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = ((prediction.predicted_mean - endogenous_test)**2).mean()\n",
    "rmse = np.sqrt(mse)\n",
    "print('The MSE for this model is {}'.format(mse))\n",
    "print('The RMSE for this model is {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''Our model does {np.round(((baseline_rmse - rmse) / baseline_rmse * 100), \n",
    "                                    decimals=2)}% better than guessing the mean response time!''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at some stuff with call volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endogenous_train = weekly_call_volume[:-52]\n",
    "exogenous_train = weekly_call_volume_df.drop(['sum of weekly calls'], axis=1)[:-52]\n",
    "endogenous_test = weekly_call_volume[-52:]\n",
    "exogenous_test = weekly_call_volume_df.drop(['sum of weekly calls'], axis=1)[-52:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run a grid with pdq and seasonal pdq parameters calculated above and get the best AIC value\n",
    "def arima_gs(ts):\n",
    "    ans = []\n",
    "    for comb in pdq:\n",
    "        for combs in pdqs:\n",
    "            try:\n",
    "                mod = sm.tsa.statespace.SARIMAX(ts,\n",
    "                                                order=comb,\n",
    "                                                seasonal_order=combs,\n",
    "                                                enforce_stationarity=False,\n",
    "                                                enforce_invertibility=False)\n",
    "\n",
    "                output = mod.fit()\n",
    "                ans.append([comb, combs, output.aic])\n",
    "                print('ARIMA {} x {}52 : AIC Calculated ={}'.format(comb, combs, output.aic))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    # Find the parameters with minimal AIC value.\n",
    "\n",
    "    ans_df = pd.DataFrame(ans, columns=['pdq', 'pdqs', 'aic'])\n",
    "    ans_df.loc[ans_df['aic'].idxmin()]\n",
    "    print(ans_df)\n",
    "    print(ans_df.loc[ans_df['aic'].idxmin()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arima_gs(weekly_call_volume) # Use to get ideal arima params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARIMA_MODEL = sm.tsa.statespace.SARIMAX(endogenous_train,\n",
    "                                exog = exogenous_train,\n",
    "                                order=(1, 0, 1),\n",
    "                                seasonal_order=(0, 1, 1, 52),\n",
    "                                enforce_stationarity=False,\n",
    "                                enforce_invertibility=False)\n",
    "\n",
    "output = ARIMA_MODEL.fit()\n",
    "\n",
    "print(output.summary().tables[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.plot_diagnostics(figsize=(15, 8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = output.get_prediction(start = endogenous_test.index[0],\n",
    "                                    end = endogenous_test.index[-1],\n",
    "                                    exog = exogenous_test,\n",
    "                                    dynamic = False)\n",
    "\n",
    "pred_conf = prediction.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the static forecast with confidence intervals.\n",
    "\n",
    "ax = weekly_call_volume[-100:].plot(label='observed', figsize=(18, 8))\n",
    "prediction.predicted_mean.plot(label='Static Forecast', ax=ax)\n",
    "\n",
    "# ax.fill_between(pred_conf.index,\n",
    "#                 pred_conf.iloc[:, 0],\n",
    "#                 pred_conf.iloc[:, 1], color='g', alpha=.3)\n",
    "\n",
    "# ax.fill_betweenx(ax.get_ylim(), \n",
    "#                  weekly_average_response_time[-50:-49].index[0], \n",
    "#                  '2017-12-31', \n",
    "#                  alpha=.1, zorder=-1)\n",
    "\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Avg Weekly Call Volume')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_vol_mean = np.zeros((len(weekly_call_volume),1))\n",
    "call_vol_mean.fill(np.mean(weekly_call_volume[:-52]))\n",
    "call_vol_mean = pd.DataFrame(call_vol_mean, \n",
    "                                      index=weekly_call_volume.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_mse = np.mean((call_vol_mean[-52:][0] - endogenous_test)**2)\n",
    "baseline_rmse = np.sqrt(baseline_mse)\n",
    "print('The MSE when guessing the mean is {}'.format(baseline_mse))\n",
    "print('The RMSE when guessing the mean is {}'.format(baseline_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = ((prediction.predicted_mean - endogenous_test)**2).mean()\n",
    "rmse = np.sqrt(mse)\n",
    "print('The MSE for this model is {}'.format(mse))\n",
    "print('The RMSE for this model is {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'''Our model does {np.round(((baseline_rmse - rmse) / baseline_rmse * 100), \n",
    "                                    decimals=2)}% better than guessing the mean call volume!''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Our model is off by about {np.round((rmse/7),2)} calls per day on average.')\n",
    "print(f'There are usually around {np.round((26908.908046/7),2)} calls per day.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_call_volume_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_average_response_time_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_average_response_time_df.nlargest(10, 'avg_response_time_min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_average_response_time_df.nsmallest(10, 'avg_response_time_min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_call_volume_df.nlargest(10, 'sum of weekly calls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_call_volume_df.nsmallest(10, 'sum of weekly calls')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Bayes]",
   "language": "python",
   "name": "conda-env-Bayes-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
